{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/Kannada-MNIST/sample_submission.csv\n",
      "/kaggle/input/Kannada-MNIST/test.csv\n",
      "/kaggle/input/Kannada-MNIST/Dig-MNIST.csv\n",
      "/kaggle/input/Kannada-MNIST/train.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train=pd.read_csv('../input/Kannada-MNIST/train.csv')\n",
    "test=pd.read_csv('../input/Kannada-MNIST/test.csv')\n",
    "sample_sub=pd.read_csv('../input/Kannada-MNIST/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000,), (60000, 784))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_full = train.label\n",
    "x_full = train.copy()\n",
    "x_full.drop(columns = 'label', inplace = True)\n",
    "y_full.shape, x_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = test.copy()\n",
    "x_test.drop(columns = 'id', inplace = True)\n",
    "x_test.shape\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((42000, 784), (42000,), (18000, 784), (18000,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x_full, y_full, test_size=0.30, random_state=0)\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train /= 255\n",
    "x_val /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualize the data set\n",
    "\n",
    "index = 3\n",
    "plt.imshow(x_train.iloc[index].values.reshape(28,28))\n",
    "y_train.iloc[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building a CNN model\n",
    "\n",
    "#reshape the data\n",
    "x_train_new = x_train.values.reshape(-1,28,28,1)\n",
    "x_val_new = x_val.values.reshape(-1,28,28,1)\n",
    "x_test_new = x_test.values.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((42000, 28, 28, 1), (42000, 784))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_new.shape, x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, (3,3), padding='same', input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"),\n",
    "    tf.keras.layers.LeakyReLU(alpha=0.1),\n",
    "    tf.keras.layers.Conv2D(64,  (3,3), padding='same'),\n",
    "    tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"),\n",
    "    tf.keras.layers.LeakyReLU(alpha=0.1),\n",
    "    tf.keras.layers.Conv2D(64,  (3,3), padding='same'),\n",
    "    tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"),\n",
    "    tf.keras.layers.LeakyReLU(alpha=0.1),\n",
    "\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(128, (3,3), padding='same'),\n",
    "    tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"),\n",
    "    tf.keras.layers.LeakyReLU(alpha=0.1),\n",
    "    tf.keras.layers.Conv2D(128, (3,3), padding='same'),\n",
    "    tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"),\n",
    "    tf.keras.layers.LeakyReLU(alpha=0.1),\n",
    "    tf.keras.layers.Conv2D(128, (3,3), padding='same'),\n",
    "    tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"),\n",
    "    tf.keras.layers.LeakyReLU(alpha=0.1),\n",
    "    \n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Dropout(0.2),    \n",
    "    \n",
    "    tf.keras.layers.Conv2D(256, (3,3), padding='same'),\n",
    "    tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"),\n",
    "    tf.keras.layers.LeakyReLU(alpha=0.1),\n",
    "    tf.keras.layers.Conv2D(256, (3,3), padding='same'),\n",
    "    tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"),##\n",
    "    tf.keras.layers.LeakyReLU(alpha=0.1),\n",
    "\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    \n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(256),\n",
    "    tf.keras.layers.LeakyReLU(alpha=0.1),\n",
    "    \n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 64)        640       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 14, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 14, 14, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 14, 14, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 7, 7, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 7, 7, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 7, 7, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 7, 7, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               590080    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 1,926,794\n",
      "Trainable params: 1,924,106\n",
      "Non-trainable params: 2,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_train = x_train.shape[0] // 64\n",
    "step_val = x_val.shape[0] // 64\n",
    "\n",
    "learning_rate_reduction = tf.keras.callbacks.ReduceLROnPlateau( \n",
    "    monitor='loss',    # Quantity to be monitored.\n",
    "    factor=0.25,       # Factor by which the learning rate will be reduced. new_lr = lr * factor\n",
    "    patience=2,        # The number of epochs with no improvement after which learning rate will be reduced.\n",
    "    verbose=1,         # 0: quiet - 1: update messages.\n",
    "    mode=\"auto\",       # {auto, min, max}. In min mode, lr will be reduced when the quantity monitored has stopped decreasing; \n",
    "                       # in the max mode it will be reduced when the quantity monitored has stopped increasing; \n",
    "                       # in auto mode, the direction is automatically inferred from the name of the monitored quantity.\n",
    "    min_delta=0.0001,  # threshold for measuring the new optimum, to only focus on significant changes.\n",
    "    cooldown=0,        # number of epochs to wait before resuming normal operation after learning rate (lr) has been reduced.\n",
    "    min_lr=0.00001     # lower bound on the learning rate.\n",
    "    )\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=300, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#adding data augmentation\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False,\n",
    "        shear_range = 10)\n",
    "\n",
    "\n",
    "datagen.fit(x_train_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(datagen.flow(x_train_new, y_train, batch_size=64),\n",
    "                              steps_per_epoch=len(x_train)//64,\n",
    "                              epochs=5,\n",
    "                              validation_data=(x_val_new, y_val),\n",
    "                              validation_steps=50,\n",
    "                              callbacks=[learning_rate_reduction, es],\n",
    "                              verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_val_new, y_val, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_label = model.predict_classes(x_test_new, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = test['id'].reset_index(drop = True)\n",
    "output = pd.concat([output, pd.DataFrame(y_label)], axis = 1)\n",
    "output.columns = (['id', 'label'])\n",
    "\n",
    "#Export\n",
    "output.to_csv(\"submission.csv\",index=False)\n",
    "#0.9900 private leaderboard; top 5%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
